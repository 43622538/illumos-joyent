#!/sbin/sh
#
# CDDL HEADER START
#
# The contents of this file are subject to the terms of the
# Common Development and Distribution License (the "License").
# You may not use this file except in compliance with the License.
#
# You can obtain a copy of the license at usr/src/OPENSOLARIS.LICENSE
# or http://www.opensolaris.org/os/licensing.
# See the License for the specific language governing permissions
# and limitations under the License.
#
# When distributing Covered Code, include this CDDL HEADER in each
# file and include the License file at usr/src/OPENSOLARIS.LICENSE.
# If applicable, add the following below this CDDL HEADER, with the
# fields enclosed by brackets "[]" replaced with your own identifying
# information: Portions Copyright [yyyy] [name of copyright owner]
#
# CDDL HEADER END
#
#
# Copyright (c) 2004, 2010, Oracle and/or its affiliates. All rights reserved.

. /lib/svc/share/smf_include.sh

ZPOOL=`svcprop -p config/zpool $SMF_FMRI 2>/dev/null`
ZPOOL=${ZPOOL:-zones}

MANFDS=$ZPOOL/manifests

#
# The following is a list of SMF svcs which could be run in a zone, but
# which we're not currently installing on our live image.  If we add any
# of these to the image and we want it to also be available in zones,
# then we need to move the entry to the MANFLIST.
#
# application/cups.xml
# application/font/fc-cache.xml
# application/graphical-login/gdm.xml
# application/management/net-snmp.xml
# application/management/seaport.xml
# application/management/snmpdx.xml
# application/opengl/ogl-select.xml
# application/print/service-selector.xml
# application/security/tcsd.xml
# application/x11/x11-server.xml
# application/x11/xfs.xml
# application/x11/xvnc-inetd.xml
# network/ldap/client.xml
# network/rpc/keyserv.xml
# network/socket-filter-kssl.xml
# network/ssl/kssl-proxy.xml
# network/nfs/rquota.xml
# network/smb/server.xml
# network/dns/server.xml
# network/ftp.xml
# network/finger.xml
# network/comsat.xml
# network/rpc/rstat.xml
# network/rpc/rusers.xml
# network/rpc/spray.xml
# network/rpc/wall.xml
# network/talk.xml
# network/ntp.xml
# network/sendmail-client.xml
# network/smtp-sendmail.xml
# network/telnet.xml
# network/wpa.xml
# network/rpc/gss.xml
# network/security/kadmin.xml
# network/security/krb5kdc.xml
# network/security/ktkt_warn.xml
# network/rpc/smserver.xml
# network/nfs/cbd.xml
# network/nfs/mapid.xml
# network/nfs/status.xml
# network/smb/client.xml
# network/ipmievd.xml
# network/nis/client.xml
# network/rpc/rex.xml
# network/http-apache22.xml
# system/consolekit.xml
# system/device/devices-audio.xml
# system/fm/notify-params.xml
# system/install/system-config.xml
# system/pkgserv.xml
# system/sac.xml
#

#
# The following is a list of SMF svcs which are installed on our live image and
# which could be run in a zone, but which we choose not to run in our zones.
# If we ever do want to run any of these, move the entry to the MANFLIST.
#
# network/nfs/client.xml
# network/nfs/nlockmgr.xml
# system/boot-archive-update.xml
# system/boot-archive.xml
# system/boot-config.xml
#

#
# The following is a list of SMF svc manifests under lib/svc/manifest.  These
# are available on our live image and are runnable in a zone.  Since the zones
# are sharing the base file system with the global zone, we set up so that
# these svcs are configured in the zone.
#
MANFLIST="\
	milestone/multi-user-server.xml \
	milestone/multi-user.xml \
	milestone/name-services.xml \
	milestone/network.xml \
	milestone/single-user.xml \
	milestone/sysconfig.xml \
	network/bridge.xml \
	network/dlmgmt.xml \
	network/dns/client.xml \
	network/dns/install.xml \
	network/dns/multicast.xml \
	network/forwarding.xml \
	network/inetd-upgrade.xml \
	network/inetd.xml \
	network/ipfilter.xml \
	network/ipsec/ike.xml \
	network/ipsec/ipsecalgs.xml \
	network/ipsec/manual-key.xml \
	network/ipsec/policy.xml \
	network/login.xml \
	network/network-initial.xml \
	network/network-install.xml \
	network/network-ipmgmt.xml \
	network/network-ipqos.xml \
	network/network-iptun.xml \
	network/network-location.xml \
	network/network-loopback.xml \
	network/network-netcfg.xml \
	network/network-netmask.xml \
	network/network-physical.xml \
	network/network-routing-setup.xml \
	network/network-service.xml \
	network/nfs/server.xml \
	network/rexec.xml \
	network/routing/legacy-routing.xml \
	network/routing/ndp.xml \
	network/routing/rdisc.xml \
	network/routing/ripng.xml \
	network/routing/route.xml \
	network/rpc/bind.xml \
	network/shares/group.xml \
	network/shares/reparsed.xml \
	network/shell.xml \
	network/slp.xml \
	network/ssh.xml \
	system/auditd.xml \
	system/consadm.xml \
	system/console-login.xml \
	system/coreadm.xml \
	system/cron.xml \
	system/cryptosvc.xml \
	system/device/allocate.xml \
	system/device/devices-local.xml \
	system/device/mpxio-upgrade.xml \
	system/early-manifest-import.xml \
	system/extended-accounting.xml \
	system/filesystem/autofs.xml \
	system/filesystem/joyent-fs.xml \
	system/filesystem/local-fs.xml \
	system/filesystem/minimal-fs.xml \
	system/filesystem/root-fs.xml \
	system/filesystem/usr-fs.xml \
	system/fmd.xml \
	system/hostid.xml \
	system/hotplug.xml \
	system/identity.xml \
	system/idmap.xml \
	system/keymap.xml \
	system/logadm-upgrade.xml \
	system/manifest-import.xml \
	system/name-service-cache.xml \
	system/pfexecd.xml \
	system/rbac.xml \
	system/rcap.xml \
	system/rmtmpfiles.xml \
	system/sar.xml \
	system/svc/global.xml \
	system/svc/restarter.xml \
	system/system-log.xml \
	system/utmp.xml \
	system/vtdaemon.xml"

#
# If we're running off of a live-image, setup a zone-specific manifest
# dataset that we can mount on the zone's /lib/svc/manifest directory.
#
# Regenerate the manifest data each time the image boots, so that its
# always in sync with the running image (and any fixes included there).
#
setup_manifests()
{
	echo "Initializing manifest dir."
	zfs list -H -o name $MANFDS >/dev/null 2>&1 
	[ $? -eq 0 ] && zfs destroy $MANFDS
	zfs create $MANFDS
	cd /lib/svc/manifest
	for i in $MANFLIST
        do
		echo $i
        done | cpio -pdm /$MANFDS
	mkdir -m755 /$MANFDS/site
}

#
# Return a list of running, non-global zones for which a shutdown via
# "/sbin/init 0" may work (typically only Solaris zones.)
#
shutdown_zones()
{
	zoneadm list -p | nawk -F: '{
		if ($2 != "global") {
			print $2
		}
	}'
}

[ ! -x /usr/sbin/zoneadm ] && exit 0	# SUNWzoneu not installed

if [ -z "$SMF_FMRI" ]; then
	echo "this script can only be invoked by smf(5)"	
	exit $SMF_EXIT_ERR_NOSMF
fi

# Make sure working directory is / to prevent unmounting problems.
cd /
PATH=/usr/sbin:/usr/bin; export PATH

case "$1" in
'start')
	#
	# Generate the manifest, even if no zones, since zones could be
	# provisioned later.
	#
	zfs list -H -o name $ZPOOL >/dev/null 2>&1 
	[ $? -eq 0 ] && setup_manifests

	egrep -vs '^#|^global:' /etc/zones/index || exit 0  # no local zones

	#
	# Boot the installed zones for which the "autoboot" zone property is
	# set and invoke the sysboot hook for all other installed zones.
	#
	ZONES=""
	for zone in `zoneadm list -pi | nawk -F: '{
			if ($3 == "installed") {
				print $2
			}
		}'`; do
		zonecfg -z $zone info autoboot | grep "true" >/dev/null 2>&1
		if [ $? -eq 0 ]; then
			[ -z "$ZONES" ] && echo "Booting zones:\c"
			ZONES=yes
			echo " $zone\c"

			#
			# Make sure a site dir exists, it wasn't initially
			# being created.
			#
			zonepath=`zonecfg -z $zone info zonepath | cut -d: -f2`
			[ ! -d $zonepath/site ] && mkdir -m755 $zonepath/site

			#
			# zoneadmd puts itself into its own contract so
			# this service will lose sight of it.  We don't
			# support restart so it is OK for zoneadmd to
			# to be in an orphaned contract.
			#
			zoneadm -z $zone boot &
		else
			zoneadm -z $zone sysboot &
		fi
	done

	#
	# Wait for all zoneadm processes to finish before allowing the
	# start method to exit.
	#
	wait
	[ -n "$ZONES" ] && echo .
	;;

'stop')
	egrep -vs '^#|^global:' /etc/zones/index || exit 0  # no local zones
	[ "`zoneadm list`" = "global" ] && exit 0   # no zones running

	SVC_TIMEOUT=`svcprop -p stop/timeout_seconds $SMF_FMRI`

	#
	# First, try shutting down any running zones for which an "init 0" may
	# work.
	#
	MAXSHUT=`expr 3 \* $SVC_TIMEOUT \/ 4` # 3/4 of time to zone shutdown
	MAXHALT=`expr $SVC_TIMEOUT \/ 4`      # rest of time goes to halt

	zonelist=`shutdown_zones`

	if [ -n "$zonelist" ]; then
		SHUTDOWN=0
		echo "Shutting down running zones (for up to $MAXSHUT" \
		    "seconds):\c"

		for zone in $zonelist; do
			echo " $zone\c"
			zlogin -S $zone /sbin/init 0 < /dev/null >&0 2>&0 &
			SHUTDOWN=1
		done

		[ $SHUTDOWN -eq 1 ] && echo "."

		# Allow time for zones to shutdown cleanly

		while [ $MAXSHUT -gt 0 -a "`shutdown_zones`" != "" ]; do
			MAXSHUT=`expr $MAXSHUT - 1`
			sleep 1	# wait a bit longer
		done
	fi

	#
	# Second, try halting any non-global zones still running
	#
	WAITPIDS=""
	for zone in `zoneadm list`; do
		if [ "$zone" != "global" ]; then
			[ -z "$WAITPIDS" ] &&
			    echo "Zones failed to shutdown; trying to halt " \
			    "(for up to $MAXHALT seconds):\c"
			echo " $zone\c"
			zoneadm -z $zone halt &
			WAITPIDS="$WAITPIDS $!"
		fi
	done
	[ ! -z "$WAITPIDS" ] && echo .

	# Wait for the 'zoneadm halt' commands to complete.  We will let this
	# run forever, since the restart daemon will eventually kill us off
	# anyway if the halts do not complete after a certain period of time.
	wait $WAITPIDS

	# If the halts complete but a zone is still not shutdown, it might
	# be in a state like 'shutting_down' or 'down'.  So we give it some
	# time to come all the way down.

	while [ $MAXHALT -gt 0 -a "`zoneadm list`" != "global" ]; do
		MAXHALT=`expr $MAXHALT - 1`
		sleep 1	# wait a bit longer
	done

	# If there are any remaining file systems in zones, try to unmount them.
	umountall -Z

	#
	# Report on zones which failed to shutdown.
	#
	for zone in `zoneadm list`; do
		if [ "$zone" != "global" ]; then
			echo "Zone '$zone' failed to halt."
		fi
	done
	[ "`zoneadm list`" != "global" ] && exit 1   # zones still running
	;;

*)
	echo "Usage: $0 { start | stop }"
	exit 1
	;;
esac
exit 0
